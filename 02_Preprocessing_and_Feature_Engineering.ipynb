{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83891f25",
   "metadata": {},
   "source": [
    "# Preprocessing and feature engineering\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Goal\n",
    "\n",
    "The purpose of this notebook is to transform the raw wine review data into a clean, feature-rich dataset ready for the modeling phase. This involves rigorously cleaning the data, standardizing the text, and engineering new features that could improve our model's performance.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Train/test split: Partition the data at the very beginning to create a training set for development and a test set for unbiased evaluation, preventing any data leakage.\n",
    "2. Data cleaning: Systematically handle duplicates and missing values using strategies informed by our EDA, such as imputing prices based on group medians.\n",
    "3. Text preprocessing: Create a reusable pipeline to clean and standardize the wine descriptions by lowercasing, removing punctuation and stop words, and lemmatizing the text.\n",
    "4. Feature engineering: Create new, potentially predictive features, including `review_length`, `readability_score`, and a custom `value_score` to capture quality relative to price.\n",
    "5. Corpus Creation: Combine the processed text with key categorical features to create a final, unified `corpus` for each wine that our NLP models will use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7eeeda",
   "metadata": {},
   "source": [
    "## 1. Setup and imports\n",
    "\n",
    "Goal: Import necessary libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a445b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57a7e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options for pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a1d3e7",
   "metadata": {},
   "source": [
    "## 2. Data acquisition\n",
    "\n",
    "Goal: Load the raw dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e7ffb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('winemag-data-130k-v2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ceb508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with 129971 rows and 13 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset loaded with {df.shape[0]} rows and {df.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc8785f",
   "metadata": {},
   "source": [
    "## 3. Train-test split\n",
    "\n",
    "Goal: Split the data before any cleaning or preprocessing to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09db6cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into training (80%) and testing (20%) sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de6a3353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (103976, 13)\n",
      "Testing set shape:  (25995, 13)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Testing set shape:  {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d759440b",
   "metadata": {},
   "source": [
    "## 4. Data cleaning and preprocessing\n",
    "\n",
    "Goal: Clean the data by handling missing values and duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc3fa89",
   "metadata": {},
   "source": [
    "### 4.1. Handle duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "853d604f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Dropped 6409 duplicate descriptions. Shape changed from 103976 to 97567.\n",
      "Test set:  Dropped 403 duplicate descriptions. Shape changed from 25995 to 25592.\n"
     ]
    }
   ],
   "source": [
    "# We will keep the first occurrence of any duplicate descriptions. This is done first\n",
    "# to ensure our imputation calculations are based on unique data.\n",
    "\n",
    "train_before = train_df.shape[0]\n",
    "test_before = test_df.shape[0]\n",
    "\n",
    "train_df.drop_duplicates(subset=['description'], keep='first', inplace=True)\n",
    "test_df.drop_duplicates(subset=['description'], keep='first', inplace=True)\n",
    "\n",
    "train_after = train_df.shape[0]\n",
    "test_after = test_df.shape[0]\n",
    "\n",
    "print(f\"Train set: Dropped {train_before - train_after} duplicate descriptions. Shape changed from {train_before} to {train_after}.\")\n",
    "print(f\"Test set:  Dropped {test_before - test_after} duplicate descriptions. Shape changed from {test_before} to {test_after}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4251935",
   "metadata": {},
   "source": [
    "### 4.2. Handle missing essential columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee9d8c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Dropped 0 rows with missing essentials. Shape changed from 97567 to 97567.\n",
      "Test set:  Dropped 0 rows with missing essentials. Shape changed from 25592 to 25592.\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where 'description' or 'title' are missing in both sets.\n",
    "\n",
    "train_before_na = train_df.shape[0]\n",
    "test_before_na = test_df.shape[0]\n",
    "\n",
    "train_df.dropna(subset=['description', 'title'], inplace=True)\n",
    "test_df.dropna(subset=['description', 'title'], inplace=True)\n",
    "\n",
    "train_after_na = train_df.shape[0]\n",
    "test_after_na = test_df.shape[0]\n",
    "\n",
    "print(f\"Train set: Dropped {train_before_na - train_after_na} rows with missing essentials. Shape changed from {train_before_na} to {train_after_na}.\")\n",
    "print(f\"Test set:  Dropped {test_before_na - test_after_na} rows with missing essentials. Shape changed from {test_before_na} to {test_after_na}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4014c",
   "metadata": {},
   "source": [
    "### 4.3. Impute missing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a76b6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the price imputation map using only the training data to avoid data leakage.\n",
    "price_imputation_map = train_df.groupby(['country', 'variety'])['price'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30613cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the map to the training set\n",
    "train_lookup_keys = train_df[['country', 'variety']].apply(tuple, axis=1)\n",
    "train_imputed_prices = train_lookup_keys.map(price_imputation_map)\n",
    "train_df['price'] = train_df['price'].fillna(train_imputed_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3acf0e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same map to the testing set\n",
    "test_lookup_keys = test_df[['country', 'variety']].apply(tuple, axis=1)\n",
    "test_imputed_prices = test_lookup_keys.map(price_imputation_map)\n",
    "test_df['price'] = test_df['price'].fillna(test_imputed_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "665fd8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If any prices are still missing (e.g., a new country/variety in test set), fill with global median from train set\n",
    "global_median_price = train_df['price'].median()\n",
    "train_df['price'] = train_df['price'].fillna(global_median_price)\n",
    "test_df['price'] = test_df['price'].fillna(global_median_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb25a220",
   "metadata": {},
   "source": [
    "### 4.4. Handle missing categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7b23ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'is_region_missing' feature before filling NaNs\n",
    "train_df['is_region_missing'] = train_df['region_1'].isnull()\n",
    "test_df['is_region_missing'] = test_df['region_1'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4488f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns to fill\n",
    "cols_to_fill = ['region_1', 'winery', 'designation', 'region_2', 'taster_name', 'taster_twitter_handle', 'country', 'province', 'variety']\n",
    "for col in cols_to_fill:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].fillna(\"Unknown\")\n",
    "        test_df[col] = test_df[col].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa6de7",
   "metadata": {},
   "source": [
    "### 4.5. Final check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09d19bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned training set shape: (97567, 14)\n",
      "Cleaned testing set shape:  (25592, 14)\n",
      "\n",
      "Missing values after cleaning (Train):\n",
      "country                  0\n",
      "description              0\n",
      "designation              0\n",
      "points                   0\n",
      "price                    0\n",
      "province                 0\n",
      "region_1                 0\n",
      "region_2                 0\n",
      "taster_name              0\n",
      "taster_twitter_handle    0\n",
      "title                    0\n",
      "variety                  0\n",
      "winery                   0\n",
      "is_region_missing        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cleaned training set shape: {train_df.shape}\")\n",
    "print(f\"Cleaned testing set shape:  {test_df.shape}\")\n",
    "print(\"\\nMissing values after cleaning (Train):\")\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5660e2",
   "metadata": {},
   "source": [
    "## 5. Text preprocessing\n",
    "\n",
    "Goal: Standardize the review text for NLP models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cb36386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lemmatizer and stop words list\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "316736ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Applies a series of text cleaning steps.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Remove stop words and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word.isalpha()]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa01608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function to the description column\n",
    "# We'll create a new column to store the processed text\n",
    "train_df['processed_description'] = train_df['description'].apply(preprocess_text)\n",
    "test_df['processed_description'] = test_df['description'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36dccfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Earthy leather and black pepper notes play against tart cherry and raspberry flavors in this light-bodied red blended with 8% Petite Sirah. Bright acidity supports the fruit.\n",
      "Processed: earthy leather black pepper note play tart cherry raspberry flavor lightbodied red blended petite sirah bright acidity support fruit\n"
     ]
    }
   ],
   "source": [
    "# Display a before-and-after example to verify\n",
    "print(\"Original: \", train_df['description'].iloc[0])\n",
    "print(\"Processed:\", train_df['processed_description'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f5ed5",
   "metadata": {},
   "source": [
    "## 6. Feature engineering\n",
    "\n",
    "Goal: Create new features to enrich the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7777957a",
   "metadata": {},
   "source": [
    "### 6.1. Create text-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec6c99b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['review_length'] = train_df['description'].apply(lambda x: len(x.split()))\n",
    "test_df['review_length'] = test_df['description'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4361d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['readability_score'] = train_df['description'].apply(textstat.flesch_reading_ease)\n",
    "test_df['readability_score'] = test_df['description'].apply(textstat.flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c60ac4",
   "metadata": {},
   "source": [
    "### 6.2. Create \"value score\" feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c05fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create price brackets\n",
    "price_bins = [0, 20, 50, 100, 500, df['price'].max()]\n",
    "price_labels = ['0-20', '21-50', '51-100', '101-500', '500+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86bab0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['price_bracket'] = pd.cut(train_df['price'], bins=price_bins, labels=price_labels, right=False)\n",
    "test_df['price_bracket'] = pd.cut(test_df['price'], bins=price_bins, labels=price_labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b89cc5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/g0g8nw2j0jbbsk8g5j6dxdbr0000gp/T/ipykernel_14244/2168348663.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  normalization_stats = train_df.groupby(['variety', 'price_bracket'])['points'].agg(['min', 'max'])\n"
     ]
    }
   ],
   "source": [
    "# Normalize points within each variety and price bracket group\n",
    "# We calculate the normalization stats (min/max) only on the training set\n",
    "normalization_stats = train_df.groupby(['variety', 'price_bracket'])['points'].agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c9a552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_value_score(row, stats):\n",
    "    try:\n",
    "        group_stats = stats.loc[(row['variety'], row['price_bracket'])]\n",
    "        min_pts, max_pts = group_stats['min'], group_stats['max']\n",
    "        if max_pts == min_pts:\n",
    "            return 0.5 # If all wines in group have same score, give neutral value\n",
    "        else:\n",
    "            return (row['points'] - min_pts) / (max_pts - min_pts)\n",
    "    except (KeyError, ValueError):\n",
    "        return 0.5 # Default for groups not seen in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f20b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['value_score'] = train_df.apply(lambda row: calculate_value_score(row, normalization_stats), axis=1)\n",
    "test_df['value_score'] = test_df.apply(lambda row: calculate_value_score(row, normalization_stats), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ca56e0",
   "metadata": {},
   "source": [
    "### 6.3. Create final corpus for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1af762a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['corpus'] = train_df['processed_description'] + \" \" + train_df['variety'] + \" \" + train_df['country']\n",
    "test_df['corpus'] = test_df['processed_description'] + \" \" + test_df['variety'] + \" \" + test_df['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60da4498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>is_region_missing</th>\n",
       "      <th>processed_description</th>\n",
       "      <th>review_length</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>price_bracket</th>\n",
       "      <th>value_score</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104748</th>\n",
       "      <td>US</td>\n",
       "      <td>Earthy leather and black pepper notes play against tart cherry and raspberry...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>88</td>\n",
       "      <td>23.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Dry Creek Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Virginie Boone</td>\n",
       "      <td>@vboone</td>\n",
       "      <td>Hobo 2014 Zinfandel (Dry Creek Valley)</td>\n",
       "      <td>Zinfandel</td>\n",
       "      <td>Hobo</td>\n",
       "      <td>False</td>\n",
       "      <td>earthy leather black pepper note play tart cherry raspberry flavor lightbodi...</td>\n",
       "      <td>27</td>\n",
       "      <td>55.265833</td>\n",
       "      <td>21-50</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>earthy leather black pepper note play tart cherry raspberry flavor lightbodi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101219</th>\n",
       "      <td>US</td>\n",
       "      <td>This is a heavy, rich, dry Syrah. It shows forward flavors of blackberries, ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>85</td>\n",
       "      <td>25.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Sonoma County</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Bluenose 2005 Syrah (Sonoma County)</td>\n",
       "      <td>Syrah</td>\n",
       "      <td>Bluenose</td>\n",
       "      <td>False</td>\n",
       "      <td>heavy rich dry syrah show forward flavor blackberry cherry currant mocha spi...</td>\n",
       "      <td>30</td>\n",
       "      <td>81.065000</td>\n",
       "      <td>21-50</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>heavy rich dry syrah show forward flavor blackberry cherry currant mocha spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82261</th>\n",
       "      <td>US</td>\n",
       "      <td>The winery's top of the top, this is a viscous, concentrated expression of t...</td>\n",
       "      <td>Darius II</td>\n",
       "      <td>92</td>\n",
       "      <td>225.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Virginie Boone</td>\n",
       "      <td>@vboone</td>\n",
       "      <td>Darioush 2012 Darius II Cabernet Sauvignon (Napa Valley)</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Darioush</td>\n",
       "      <td>False</td>\n",
       "      <td>winery top top viscous concentrated expression grape blended merlot fruit pr...</td>\n",
       "      <td>54</td>\n",
       "      <td>43.130000</td>\n",
       "      <td>101-500</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>winery top top viscous concentrated expression grape blended merlot fruit pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36717</th>\n",
       "      <td>Austria</td>\n",
       "      <td>Dark purple, juicy wine, with spice and pepper flavors from the Zweigelt. Th...</td>\n",
       "      <td>Koenigsegg Zwei. 1</td>\n",
       "      <td>84</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Burgenland</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Schloss Halbturn 2006 Koenigsegg Zwei. 1 Zweigelt (Burgenland)</td>\n",
       "      <td>Zweigelt</td>\n",
       "      <td>Schloss Halbturn</td>\n",
       "      <td>True</td>\n",
       "      <td>dark purple juicy wine spice pepper flavor zweigelt fruit come fresh blackbe...</td>\n",
       "      <td>30</td>\n",
       "      <td>78.245000</td>\n",
       "      <td>0-20</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>dark purple juicy wine spice pepper flavor zweigelt fruit come fresh blackbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128031</th>\n",
       "      <td>France</td>\n",
       "      <td>This 20-acre vineyard produces a wine dominated by Merlot, lending the wine ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>89</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Moulis-en-Médoc</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Château Guitignan 2011  Moulis-en-Médoc</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Château Guitignan</td>\n",
       "      <td>False</td>\n",
       "      <td>vineyard produce wine dominated merlot lending wine smooth texture wine rich...</td>\n",
       "      <td>38</td>\n",
       "      <td>75.983596</td>\n",
       "      <td>21-50</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>vineyard produce wine dominated merlot lending wine smooth texture wine rich...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country  \\\n",
       "104748       US   \n",
       "101219       US   \n",
       "82261        US   \n",
       "36717   Austria   \n",
       "128031   France   \n",
       "\n",
       "                                                                            description  \\\n",
       "104748  Earthy leather and black pepper notes play against tart cherry and raspberry...   \n",
       "101219  This is a heavy, rich, dry Syrah. It shows forward flavors of blackberries, ...   \n",
       "82261   The winery's top of the top, this is a viscous, concentrated expression of t...   \n",
       "36717   Dark purple, juicy wine, with spice and pepper flavors from the Zweigelt. Th...   \n",
       "128031  This 20-acre vineyard produces a wine dominated by Merlot, lending the wine ...   \n",
       "\n",
       "               designation  points  price    province          region_1  \\\n",
       "104748             Unknown      88   23.0  California  Dry Creek Valley   \n",
       "101219             Unknown      85   25.0  California     Sonoma County   \n",
       "82261            Darius II      92  225.0  California       Napa Valley   \n",
       "36717   Koenigsegg Zwei. 1      84   12.0  Burgenland           Unknown   \n",
       "128031             Unknown      89   23.0    Bordeaux   Moulis-en-Médoc   \n",
       "\n",
       "       region_2     taster_name taster_twitter_handle  \\\n",
       "104748   Sonoma  Virginie Boone               @vboone   \n",
       "101219   Sonoma         Unknown               Unknown   \n",
       "82261      Napa  Virginie Boone               @vboone   \n",
       "36717   Unknown      Roger Voss            @vossroger   \n",
       "128031  Unknown      Roger Voss            @vossroger   \n",
       "\n",
       "                                                                 title  \\\n",
       "104748                          Hobo 2014 Zinfandel (Dry Creek Valley)   \n",
       "101219                             Bluenose 2005 Syrah (Sonoma County)   \n",
       "82261         Darioush 2012 Darius II Cabernet Sauvignon (Napa Valley)   \n",
       "36717   Schloss Halbturn 2006 Koenigsegg Zwei. 1 Zweigelt (Burgenland)   \n",
       "128031                         Château Guitignan 2011  Moulis-en-Médoc   \n",
       "\n",
       "                         variety             winery  is_region_missing  \\\n",
       "104748                 Zinfandel               Hobo              False   \n",
       "101219                     Syrah           Bluenose              False   \n",
       "82261         Cabernet Sauvignon           Darioush              False   \n",
       "36717                   Zweigelt   Schloss Halbturn               True   \n",
       "128031  Bordeaux-style Red Blend  Château Guitignan              False   \n",
       "\n",
       "                                                                  processed_description  \\\n",
       "104748  earthy leather black pepper note play tart cherry raspberry flavor lightbodi...   \n",
       "101219  heavy rich dry syrah show forward flavor blackberry cherry currant mocha spi...   \n",
       "82261   winery top top viscous concentrated expression grape blended merlot fruit pr...   \n",
       "36717   dark purple juicy wine spice pepper flavor zweigelt fruit come fresh blackbe...   \n",
       "128031  vineyard produce wine dominated merlot lending wine smooth texture wine rich...   \n",
       "\n",
       "        review_length  readability_score price_bracket  value_score  \\\n",
       "104748             27          55.265833         21-50     0.533333   \n",
       "101219             30          81.065000         21-50     0.294118   \n",
       "82261              54          43.130000       101-500     0.529412   \n",
       "36717              30          78.245000          0-20     0.200000   \n",
       "128031             38          75.983596         21-50     0.473684   \n",
       "\n",
       "                                                                                 corpus  \n",
       "104748  earthy leather black pepper note play tart cherry raspberry flavor lightbodi...  \n",
       "101219  heavy rich dry syrah show forward flavor blackberry cherry currant mocha spi...  \n",
       "82261   winery top top viscous concentrated expression grape blended merlot fruit pr...  \n",
       "36717   dark purple juicy wine spice pepper flavor zweigelt fruit come fresh blackbe...  \n",
       "128031  vineyard produce wine dominated merlot lending wine smooth texture wine rich...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the dataframe with new features\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7718b69",
   "metadata": {},
   "source": [
    "## 7. Save processed data\n",
    "\n",
    "Goal: Save the cleaned and feature-engineered dataframes for the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bbf5f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_processed.csv', index=False)\n",
    "test_df.to_csv('test_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f27f2",
   "metadata": {},
   "source": [
    "## Conclusion and key insights\n",
    "\n",
    "This notebook successfully executed the critical data preparation phase of our project. By splitting the data first and applying our cleaning steps consistently, we've created a robust foundation for model training and evaluation. The key outcome is the creation of two clean datasets, `train_processed.csv` and `test_processed.csv`, which are now free of missing values and enriched with several new features designed to capture more nuance than the text alone. The `value_score` and `readability_score` provide additional dimensions for our hybrid model, and the final `corpus` is a clean, standardized text representation of each wine. We are now fully prepared to move on to the next notebook, where we will use these processed datasets to experiment with and evaluate our different recommendation models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
