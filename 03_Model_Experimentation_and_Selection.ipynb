{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "468d70d1",
   "metadata": {},
   "source": [
    "# Model experimentation and selection\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Goal\n",
    "\n",
    "The primary goal of this notebook is to systematically build, evaluate, and compare our four distinct recommendation models. By using a consistent set of quantitative and qualitative metrics, we will determine which approach provides the most accurate, relevant, and explainable recommendations, ultimately selecting the single best model to power our final application.\n",
    "\n",
    "### Steps\n",
    "1. Load data: Import the cleaned and feature-engineered datasets from the previous notebook.\n",
    "2. Define evaluation: Create reusable functions to measure model performance based on variety match, country match, point differential, and qualitative case studies.\n",
    "3. Model 1 - TF-IDF: Build and evaluate a baseline model using TF-IDF and cosine similarity.\n",
    "4. Model 2 - Sentence Transformer: Build and evaluate a model using a pre-trained sentence embedding model.\n",
    "5. Model 3 - Custom Word2Vec: Build and evaluate a model using custom word embeddings trained on our specific wine corpus.\n",
    "6. Model 4 - Hybrid: Build and evaluate a custom hybrid model that combines the best text-based approach with our engineered numerical features.\n",
    "7. Final Selection: Compare all results and save the components of the winning model for the next phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e4bfb2",
   "metadata": {},
   "source": [
    "## 1. Setup and imports\n",
    "\n",
    "Goal: Import necessary libraries and load the processed datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cee6a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, manhattan_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import nltk\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e65c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options for pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c85e16e",
   "metadata": {},
   "source": [
    "## 2. Data acquisition\n",
    "\n",
    "Goal: Load the cleaned and feature-engineered data from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a02150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_processed.csv')\n",
    "test_df = pd.read_csv('test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1db3b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'price_bracket' column was useful for creating the value_score,\n",
    "# but it's a categorical type that might cause issues later.\n",
    "# We'll convert it to a string for simplicity.\n",
    "train_df['price_bracket'] = train_df['price_bracket'].astype(str)\n",
    "test_df['price_bracket'] = test_df['price_bracket'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc7f9b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (97567, 20)\n",
      "Testing set shape:  (25592, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Testing set shape:  {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bbd2c5",
   "metadata": {},
   "source": [
    "## 3. Define evaluation metrics\n",
    "\n",
    "Goal: Create functions to objectively measure the performance of our recommendation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ec77f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(recommendations_df):\n",
    "    \"\"\"\n",
    "    Calculates performance metrics based on a dataframe of recommendations.\n",
    "    \"\"\"\n",
    "    # Variety Match Rate\n",
    "    # Calculates the percentage of recommendations where at least one recommended wine has the same variety\n",
    "    variety_match_at_least_one = recommendations_df.apply(\n",
    "        lambda row: row['variety'] in row['recommended_varieties'], axis=1\n",
    "    ).mean()\n",
    "\n",
    "    # Country Match Rate\n",
    "    # Calculates the percentage of recommendations where at least one recommended wine is from the same country\n",
    "    country_match_at_least_one = recommendations_df.apply(\n",
    "        lambda row: row['country'] in row['recommended_countries'], axis=1\n",
    "    ).mean()\n",
    "\n",
    "    # Average Point Differential\n",
    "    # Calculates the average difference in points\n",
    "    point_diff = (recommendations_df['recommended_points'].apply(np.mean) - recommendations_df['points']).abs().mean()\n",
    "\n",
    "    print(f\"Variety Match Rate (at least one): {variety_match_at_least_one:.2%}\")\n",
    "    print(f\"Country Match Rate (at least one): {country_match_at_least_one:.2%}\")\n",
    "    print(f\"Average Point Differential: {point_diff:.2f} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0acd9f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(test_indices, similarity_matrix, train_dataframe, test_dataframe, top_n=5):\n",
    "    \"\"\"\n",
    "    Generates recommendations for a given set of test indices.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    # The similarity matrix is (test_samples x train_samples)\n",
    "    # We iterate through the rows of the similarity matrix, which correspond to the test_indices\n",
    "    for i, test_idx in enumerate(test_indices):\n",
    "        # Get the similarity scores for the i-th test wine against all training wines\n",
    "        sim_scores = list(enumerate(similarity_matrix[i]))\n",
    "        # Sort the wines based on the similarity scores\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        # Get the scores of the top_n most similar wines\n",
    "        sim_scores = sim_scores[:top_n]\n",
    "        # Get the training wine indices\n",
    "        train_wine_indices = [i[0] for i in sim_scores]\n",
    "        \n",
    "        # Get the details of the recommended wines from the training dataframe\n",
    "        rec_wines = train_dataframe.iloc[train_wine_indices]\n",
    "        \n",
    "        # Get the details of the original test wine\n",
    "        original_wine = test_dataframe.loc[test_idx]\n",
    "        \n",
    "        results.append({\n",
    "            'variety': original_wine['variety'],\n",
    "            'country': original_wine['country'],\n",
    "            'points': original_wine['points'],\n",
    "            'recommended_varieties': list(rec_wines['variety']),\n",
    "            'recommended_countries': list(rec_wines['country']),\n",
    "            'recommended_points': list(rec_wines['points'])\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec59675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_tfidf_recommendation(original_corpus, recommended_corpus, vectorizer):\n",
    "    \"\"\"\n",
    "    Finds the shared top keywords between two documents based on TF-IDF scores.\n",
    "    \"\"\"\n",
    "    # Create a set of words from the original corpus for fast lookup\n",
    "    original_words = set(original_corpus.split())\n",
    "    \n",
    "    # Get feature names and their corresponding IDF scores from the vectorizer\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "    idf_scores = vectorizer.idf_\n",
    "    \n",
    "    # Create a dictionary of word -> idf_score\n",
    "    word_idf_dict = dict(zip(feature_names, idf_scores))\n",
    "    \n",
    "    # Find shared words that are also in our feature set\n",
    "    shared_words = [word for word in recommended_corpus.split() if word in original_words and word in word_idf_dict]\n",
    "    \n",
    "    # Score shared words by their IDF value (lower IDF means more common/less important)\n",
    "    # We want words with high IDF, so we sort in ascending order and take the last ones.\n",
    "    shared_words.sort(key=lambda word: word_idf_dict.get(word, 0))\n",
    "    \n",
    "    # Return the top 5 most important shared words (highest IDF)\n",
    "    return shared_words[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d60585e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_study(original_wine_index, similarity_matrix, train_dataframe, test_dataframe, vectorizer=None):\n",
    "    \"\"\"\n",
    "    Performs a deep dive into a single recommendation.\n",
    "    \"\"\"\n",
    "    # The similarity_matrix for a single case study is shape (1, n_train_samples).\n",
    "    # We just need the first (and only) row.\n",
    "    sim_scores = list(enumerate(similarity_matrix[0]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[:5] # Get top 5 recommendations\n",
    "    train_wine_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    original_wine = test_dataframe.loc[original_wine_index]\n",
    "    recommended_wines = train_dataframe.iloc[train_wine_indices]\n",
    "    \n",
    "    print(\"--- CASE STUDY ---\")\n",
    "    print(f\"Original Wine: {original_wine['title']} ({original_wine['variety']}, {original_wine['points']} pts)\")\n",
    "    print(f\"Description: {original_wine['description']}\\n\")\n",
    "    \n",
    "    print(\"--- Top 5 Recommendations ---\")\n",
    "    for i, (idx, score) in enumerate(zip(train_wine_indices, sim_scores)):\n",
    "        rec_wine = train_dataframe.iloc[idx]\n",
    "        print(f\"{i+1}. {rec_wine['title']} ({rec_wine['variety']}, {rec_wine['points']} pts) - Similarity: {score[1]:.4f}\")\n",
    "        print(f\"   Description: {rec_wine['description']}\")\n",
    "        \n",
    "        # If a vectorizer is provided, show the explainability\n",
    "        if vectorizer:\n",
    "            shared_keywords = explain_tfidf_recommendation(original_wine['corpus'], rec_wine['corpus'], vectorizer)\n",
    "            print(f\"   Shared Key Terms: {shared_keywords}\\n\")\n",
    "        else:\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e82e0dc",
   "metadata": {},
   "source": [
    "## 4. Approach 1: TF-IDF model\n",
    "\n",
    "Goal: Build and evaluate a recommendation model using TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5afc159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create and fit the TF-IDF Vectorizer on the training data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_train_vectors = tfidf_vectorizer.fit_transform(train_df['corpus'].fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a5b7079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Transform the full test data using the fitted vectorizer\n",
    "tfidf_test_vectors = tfidf_vectorizer.transform(test_df['corpus'].fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "706bfdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Select a sample of the test set for evaluation to avoid memory issues\n",
    "# We'll use a sample of 1000 test wines for faster evaluation\n",
    "test_sample = test_df.sample(n=1000, random_state=42)\n",
    "test_sample_indices = test_sample.index\n",
    "# We need the original index locations to slice the test vectors matrix\n",
    "test_sample_locs = [test_df.index.get_loc(i) for i in test_sample_indices]\n",
    "sample_test_vectors = tfidf_test_vectors[test_sample_locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e14f5368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Calculate the cosine similarity ONLY for the sample against the train vectors\n",
    "# The resulting matrix will have a manageable shape of (1000, n_train_samples)\n",
    "tfidf_similarity_matrix = cosine_similarity(sample_test_vectors, tfidf_train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "587dc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate recommendations for our sample\n",
    "tfidf_recommendations = get_recommendations(\n",
    "    test_indices=test_sample_indices,\n",
    "    similarity_matrix=tfidf_similarity_matrix,\n",
    "    train_dataframe=train_df,\n",
    "    test_dataframe=test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "514393d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variety Match Rate (at least one): 93.00%\n",
      "Country Match Rate (at least one): 98.60%\n",
      "Average Point Differential: 1.70 points\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the model's performance (Quantitative)\n",
    "evaluate_model(tfidf_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c97809",
   "metadata": {},
   "source": [
    "The TF-IDF model has established a very strong baseline performance. The high Variety Match Rate (93%) and exceptionally high Country Match Rate (98.6%) show that this keyword-based approach is excellent at identifying and matching the most important explicit features in the wine descriptions. Furthermore, the low Average Point Differential (1.70) indicates that the recommendations are consistently within a similar quality tier. These results demonstrate that even a simple TF-IDF model can be highly effective for this task, setting a high bar for the more complex semantic models to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeb9b36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CASE STUDY ---\n",
      "Original Wine: Beresford 2013 Single Vineyard Chardonnay (McLaren Vale) (Chardonnay, 82 pts)\n",
      "Description: Let me confess upfront: creamed corn was one of my favorite side dishes when I was a child. That said, it's not something I like in my wine, and this medium-bodied Chardonnay shows an excess of those sweet corn and lactic aromas and flavors.\n",
      "\n",
      "--- Top 5 Recommendations ---\n",
      "1. El Enemigo 2013 Chardonnay (Mendoza) (Chardonnay, 85 pts) - Similarity: 0.3783\n",
      "   Description: This ripe offering smells of corn, baked apple and oak. It's creamy and woody in the mouth, with modest acidity. Flavors of creamed corn, caramel and soft melon finish plump, with a baked quality. It lacks vivacity.\n",
      "   Shared Key Terms: ['flavor', 'corn', 'corn', 'creamed']\n",
      "\n",
      "2. Männle 2012 Chardonnay (Itata Valley) (Chardonnay, 80 pts) - Similarity: 0.3753\n",
      "   Description: Aromas of sweet corn and melon are not convincing. This has little in the way of mouthfeel or substance; flavors of candied fruits taste like corn and wheat, while the finish is spineless.\n",
      "   Shared Key Terms: ['aroma', 'sweet', 'like', 'corn', 'corn']\n",
      "\n",
      "3. El Enemigo 2015 Chardonnay (Mendoza) (Chardonnay, 87 pts) - Similarity: 0.3609\n",
      "   Description: This golden Chardonnay is loaded with rich, oaky aromas of corn pudding, butterscotch, baked apple and wood grain. Plump and soft on the palate, this tastes of baked apple, creamed corn and buttery oak, with popcorn to the finish. Drink through 2017.\n",
      "   Shared Key Terms: ['aroma', 'chardonnay', 'corn', 'corn', 'creamed']\n",
      "\n",
      "4. Ryan Patrick 2013 Reserve Chardonnay (Columbia Valley (WA)) (Chardonnay, 90 pts) - Similarity: 0.3512\n",
      "   Description: From a warm vintage, this aromatic offering has notes of candy corn, corn silk, pear and tropical fruit. It's full bodied with sweet fruit flavors that have a creamy feel and lead to a lingering finish.\n",
      "   Shared Key Terms: ['flavor', 'sweet', 'corn', 'corn']\n",
      "\n",
      "5. Kumeu River 2010 Estate Chardonnay (Kumeu) (Chardonnay, 90 pts) - Similarity: 0.3399\n",
      "   Description: A blend assembled from several vineyards, Kumeu River's 2010 Estate Chardonnay is a medium-bodied, plushly textured wine. Toast and citrus aromas lead the way, followed by flavors that hint at creamed corn and plenty of vibrant pineapple. Drink it over the next few years.\n",
      "   Shared Key Terms: ['aroma', 'chardonnay', 'mediumbodied', 'corn', 'creamed']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Evaluate the model's performance (Qualitative)\n",
    "# We need the full similarity matrix for the case study, so we'll compute it for the specific wine we choose\n",
    "case_study_index = test_sample_indices[0] # Just pick the first wine from our sample\n",
    "case_study_loc = test_df.index.get_loc(case_study_index)\n",
    "case_study_similarity_matrix = cosine_similarity(tfidf_test_vectors[case_study_loc:case_study_loc+1], tfidf_train_vectors)\n",
    "case_study(case_study_index, case_study_similarity_matrix, train_df, test_df, vectorizer=tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be61c0e",
   "metadata": {},
   "source": [
    "This case study perfectly illustrates both the power and the primary weakness of the TF-IDF model. The model was exceptionally successful at identifying the most unique and heavily weighted term in the original review: \"creamed corn.\" As a result, it delivered five highly relevant recommendations that are all Chardonnays and all share this very specific, unusual flavor note. However, the model lacks any understanding of sentiment or context; it doesn't know that \"creamed corn\" was mentioned as an undesirable quality. This highlights that while TF-IDF is excellent at literal keyword matching, it can't grasp the user's actual preference, which is a key limitation we hope to address with more advanced semantic models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5014be",
   "metadata": {},
   "source": [
    "## 5. Approach 2: pre-trained sentence embeddings\n",
    "\n",
    "Goal: Build and evaluate a model using a pre-trained Sentence Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "989a9ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the pre-trained model\n",
    "# 'all-MiniLM-L6-v2' is a fast and effective baseline model.\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e6315f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e6b60120e04af4b37c499d7ed1d0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Generate embeddings for the training data\n",
    "sbert_train_vectors = model.encode(train_df['corpus'].fillna('').tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65c65896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734d5ca8d3614769901e63d8926477ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3: Generate embeddings for the test sample\n",
    "sbert_test_sample_vectors = model.encode(test_sample['corpus'].fillna('').tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "228069de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Calculate cosine similarity between the test sample and all training data\n",
    "sbert_similarity_matrix = cosine_similarity(sbert_test_sample_vectors, sbert_train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0df741fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate recommendations for the sample\n",
    "sbert_recommendations = get_recommendations(\n",
    "    test_indices=test_sample_indices,\n",
    "    similarity_matrix=sbert_similarity_matrix,\n",
    "    train_dataframe=train_df,\n",
    "    test_dataframe=test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02a5408c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variety Match Rate (at least one): 89.30%\n",
      "Country Match Rate (at least one): 97.10%\n",
      "Average Point Differential: 1.88 points\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the model's performance (Quantitative)\n",
    "evaluate_model(sbert_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f892135c",
   "metadata": {},
   "source": [
    "The Sentence Transformer model, which is designed to understand the meaning of the text, performs slightly worse than the TF-IDF baseline on these specific metrics. The Variety Match Rate drops to 89.3%, and the Average Point Differential increases to 1.88, indicating that it's less precise at matching the exact grape and quality score. This result suggests that for matching explicit, factual information that is present as keywords in the text (like 'Chardonnay' or 'USA'), the direct keyword-matching approach of TF-IDF is more effective. The true test for this semantic model will be in the qualitative review, where we can see if it's recommending wines that are similar in style and feel, even if they aren't an exact match on paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f84febfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CASE STUDY ---\n",
      "Original Wine: Beresford 2013 Single Vineyard Chardonnay (McLaren Vale) (Chardonnay, 82 pts)\n",
      "Description: Let me confess upfront: creamed corn was one of my favorite side dishes when I was a child. That said, it's not something I like in my wine, and this medium-bodied Chardonnay shows an excess of those sweet corn and lactic aromas and flavors.\n",
      "\n",
      "--- Top 5 Recommendations ---\n",
      "1. Dutton Estate 2009 Warren's Collection Chardonnay (Russian River Valley) (Chardonnay, 84 pts) - Similarity: 0.6906\n",
      "   Description: The poster child for too much oak. Swamps with buttered toast, caramel, butterscotch and vanilla flavors that are so sweet, it's almost like a dessert wine. There's lots of tangerines, pineapples, apricots and apples, but those barrel influences are too much.\n",
      "\n",
      "\n",
      "2. Millbrook 2013 Proprietor's Special Reserve Chardonnay (Hudson River Region) (Chardonnay, 84 pts) - Similarity: 0.6896\n",
      "   Description: Pronounced notes of butter, cheese and canned cream corn dominate this savory Chardonnay. It's a rather fat, cream-textured wine but sunny tangerine acidity and fresher notes of apple and pear flavors do get a peek through the midpalate.\n",
      "\n",
      "\n",
      "3. Black's Station 2015 Estate Bottled Chardonnay (Dunnigan Hills) (Chardonnay, 88 pts) - Similarity: 0.6853\n",
      "   Description: This big, full-bodied wine is unabashedly bold and brassy, from the aromas of toasted oak to the buttery flavors and vanilla finish. While dry, it has a rich texture and the near-sweetness of ripe varietal flavors.\n",
      "\n",
      "\n",
      "4. Martha Clara 2010 Estate Reserve Chardonnay (North Fork of Long Island) (Chardonnay, 86 pts) - Similarity: 0.6826\n",
      "   Description: Bright apple and lemon aromas, along with a hint of sweet creamed corn, introduce this generously oaked Chardonnay. It's dry in style but bold on the palate with a rich, luxurious mouthfeel. Finishes moderately long with a lingering slick of butter.\n",
      "\n",
      "\n",
      "5. Sparkman 2014 Lumière Chardonnay (Columbia Valley (WA)) (Chardonnay, 90 pts) - Similarity: 0.6821\n",
      "   Description: Aromas of cream and corn on the cob are followed by lively full-bodied fruit flavors with plenty of toasty accents. It offers an appealing sense of texture along with a lovely sense of balance.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Evaluate the model's performance (Qualitative)\n",
    "# We need to generate the embedding for the single case study wine\n",
    "case_study_corpus = test_df.loc[case_study_index]['corpus']\n",
    "case_study_vector = model.encode([case_study_corpus])\n",
    "sbert_case_study_similarity = cosine_similarity(case_study_vector, sbert_train_vectors)\n",
    "\n",
    "# We pass vectorizer=None to trigger the embedding explanation method\n",
    "case_study(case_study_index, sbert_case_study_similarity, train_df, test_df, vectorizer=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc3ee63",
   "metadata": {},
   "source": [
    "This case study demonstrates the Sentence Transformer's ability to understand the overall style of a wine, moving beyond simple keyword matching. While it still recommended several wines with the \"creamed corn\" note, it also identified Chardonnays that were similar in a broader sense—described as \"oaky,\" \"buttery,\" \"creamy,\" and \"rich.\" For example, the first recommendation, described as a \"poster child for too much oak,\" is a perfect stylistic match for a wine criticized for its \"excess\" of lactic flavors, even if the specific keywords differ. This shows the model is capturing the semantic essence of a rich, bold Chardonnay style, although, like the TF-IDF model, it still fails to grasp the negative sentiment of the original review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2ced8a",
   "metadata": {},
   "source": [
    "## 6. Approach 3: Custom word embeddings (Word2Vec)\n",
    "\n",
    "Goal: Build and evaluate a model using custom Word2Vec embeddings trained on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad5b7d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare tokenized sentences from the training corpus\n",
    "# We need a list of lists of words for the Word2Vec model\n",
    "tokenized_corpus = [nltk.word_tokenize(doc) for doc in train_df['corpus'].fillna('')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed269802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the Word2Vec model\n",
    "custom_w2v_model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b991351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a function to get the average vector for a document\n",
    "def get_average_vector(tokens, model, vector_size):\n",
    "    vec = np.zeros(vector_size)\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        if word in model.wv:\n",
    "            vec += model.wv[word]\n",
    "            count += 1\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a6d01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate document vectors for train and test sets\n",
    "w2v_train_vectors = np.array([get_average_vector(nltk.word_tokenize(doc), custom_w2v_model, 100) for doc in train_df['corpus'].fillna('')])\n",
    "w2v_test_sample_vectors = np.array([get_average_vector(nltk.word_tokenize(doc), custom_w2v_model, 100) for doc in test_sample['corpus'].fillna('')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1dce8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Calculate cosine similarity\n",
    "w2v_similarity_matrix = cosine_similarity(w2v_test_sample_vectors, w2v_train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f986e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Generate recommendations\n",
    "w2v_recommendations = get_recommendations(\n",
    "    test_indices=test_sample_indices,\n",
    "    similarity_matrix=w2v_similarity_matrix,\n",
    "    train_dataframe=train_df,\n",
    "    test_dataframe=test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d895169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variety Match Rate (at least one): 83.40%\n",
      "Country Match Rate (at least one): 97.30%\n",
      "Average Point Differential: 1.60 points\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Evaluate the model (Quantitative)\n",
    "evaluate_model(w2v_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f99363",
   "metadata": {},
   "source": [
    "The custom Word2Vec model presents a very interesting trade-off. It has the lowest Variety Match Rate (83.40%) so far, indicating it's less precise at matching the exact grape type compared to the other methods. However, it achieves the best Average Point Differential (1.60), suggesting it has developed a superior, domain-specific understanding of the language related to wine quality. This model appears to be excellent at capturing the style and quality tier of a wine, even if it sometimes generalizes across different but stylistically similar varieties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "384c1e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CASE STUDY ---\n",
      "Original Wine: Beresford 2013 Single Vineyard Chardonnay (McLaren Vale) (Chardonnay, 82 pts)\n",
      "Description: Let me confess upfront: creamed corn was one of my favorite side dishes when I was a child. That said, it's not something I like in my wine, and this medium-bodied Chardonnay shows an excess of those sweet corn and lactic aromas and flavors.\n",
      "\n",
      "--- Top 5 Recommendations ---\n",
      "1. Irony 2005 Chardonnay (Napa Valley) (Chardonnay, 81 pts) - Similarity: 0.8315\n",
      "   Description: Just what many people like, an oaky, ripe, sweet Chardonnay, but purists will find it simple and pandering to public taste.\n",
      "\n",
      "\n",
      "2. Dancing Bull 2005 Chardonnay (California) (Chardonnay, 81 pts) - Similarity: 0.8287\n",
      "   Description: Something went south on this wine. It smells and tastes burnt, like it went through a fire, and the simple flavors are like the syrup in canned peaches.\n",
      "\n",
      "\n",
      "3. Vinum Cellars 2011 Chardonnay (North Coast) (Chardonnay, 83 pts) - Similarity: 0.8158\n",
      "   Description: A tropical Chardonnay with a full-bodied personality and aromas of vanilla and caramel. Priced fairly, it'll please California Chardonnay fans who like a bigger style.\n",
      "\n",
      "\n",
      "4. Cockatoo Ridge 2000 Chardonnay (Australia) (Chardonnay, 83 pts) - Similarity: 0.7992\n",
      "   Description: Simple melon and vanilla aromas and flavors in a lightweight wine. It'll go fine with carryout rotisserie chicken on a busy weeknight, when something else might be overkill.\n",
      "\n",
      "\n",
      "5. Trivento 2005 Select Chardonnay (Mendoza) (Chardonnay, 87 pts) - Similarity: 0.7917\n",
      "   Description: Round, melony and driven by aromas of pears and apples, this internationally styled wine should strike a chord among casual Chardonnay quaffers. It's kind of sweet, a little bit fat, and it finishes smooth. True to the blueprint in many ways; think California and this will complete the picture. Imported by Excelsior Wine & Spirits.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Evaluate the model (Qualitative)\n",
    "case_study_corpus_w2v = test_df.loc[case_study_index]['corpus']\n",
    "case_study_vector_w2v = np.array([get_average_vector(nltk.word_tokenize(case_study_corpus_w2v), custom_w2v_model, 100)])\n",
    "w2v_case_study_similarity = cosine_similarity(case_study_vector_w2v, w2v_train_vectors)\n",
    "case_study(case_study_index, w2v_case_study_similarity, train_df, test_df, vectorizer=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9332fa",
   "metadata": {},
   "source": [
    "This case study shows the custom Word2Vec model's sophisticated ability to understand the overall character and even the quality level of a wine from its description. Unlike the TF-IDF model, it did not fixate on the \"creamed corn\" keyword. Instead, it recommended other low-scoring Chardonnays that were described with similar negative or simplistic terms like \"pandering,\" \"burnt,\" and \"simple.\" This is a remarkable result, as it demonstrates the model learned to associate the language of a flawed, low-quality Chardonnay with other similarly described wines. It's not recommending good alternatives, but it is correctly identifying wines that belong to the same stylistic and quality cluster, proving it has learned the nuanced semantics of the wine review vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cbb44c",
   "metadata": {},
   "source": [
    "## 7. Approach 4: Custom hybrid model\n",
    "\n",
    "Goal: Combine text similarity with the engineered features for a more nuanced model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "628dd393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Normalize the numerical features ('points', 'price', 'value_score')\n",
    "# We'll use MinMaxScaler, fitting it ONLY on the training data.\n",
    "scaler = MinMaxScaler()\n",
    "numerical_features = ['points', 'price', 'value_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f49914db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill any potential NaN values in value_score before scaling\n",
    "train_df['value_score'] = train_df['value_score'].fillna(0.5)\n",
    "test_sample['value_score'] = test_sample['value_score'].fillna(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2daa8088",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numerical_scaled = scaler.fit_transform(train_df[numerical_features])\n",
    "test_sample_numerical_scaled = scaler.transform(test_sample[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e579657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Calculate similarity for each numerical feature\n",
    "# We use Manhattan distance and invert it to get a similarity score (0 to 1)\n",
    "points_sim = 1 - manhattan_distances(test_sample_numerical_scaled[:, 0].reshape(-1, 1), train_numerical_scaled[:, 0].reshape(-1, 1))\n",
    "price_sim = 1 - manhattan_distances(test_sample_numerical_scaled[:, 1].reshape(-1, 1), train_numerical_scaled[:, 1].reshape(-1, 1))\n",
    "value_sim = 1 - manhattan_distances(test_sample_numerical_scaled[:, 2].reshape(-1, 1), train_numerical_scaled[:, 2].reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5aaf3201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define weights for the hybrid score\n",
    "# Based on our findings, text is most important, followed by quality (points/value)\n",
    "weights = {\n",
    "    'text': 0.7,\n",
    "    'points': 0.15,\n",
    "    'value': 0.15\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57cb2a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Calculate the final hybrid similarity score\n",
    "# We'll use the TF-IDF similarity as our text component since it performed best on explicit features\n",
    "hybrid_similarity_matrix = (\n",
    "    weights['text'] * tfidf_similarity_matrix +\n",
    "    weights['points'] * points_sim +\n",
    "    weights['value'] * value_sim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6ee53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate recommendations\n",
    "hybrid_recommendations = get_recommendations(\n",
    "    test_indices=test_sample_indices,\n",
    "    similarity_matrix=hybrid_similarity_matrix,\n",
    "    train_dataframe=train_df,\n",
    "    test_dataframe=test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cae9ebfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variety Match Rate (at least one): 93.90%\n",
      "Country Match Rate (at least one): 99.10%\n",
      "Average Point Differential: 0.72 points\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the model (Quantitative)\n",
    "evaluate_model(hybrid_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eb4e8f",
   "metadata": {},
   "source": [
    "The hybrid model is a clear success, outperforming all previous approaches on every quantitative metric. By combining the keyword-matching strength of TF-IDF with our engineered features, it achieves an excellent Variety Match Rate (93.90%) and a near-perfect Country Match Rate (99.10%). The most impressive result, however, is the Average Point Differential, which has been dramatically reduced to just 0.72 points. This indicates that the model is not only finding stylistically similar wines but is also exceptionally good at matching their quality tier, creating a far more balanced and precise recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd9eff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Evaluate the model (Qualitative)\n",
    "# For the case study, we need to calculate the hybrid similarity for just one wine\n",
    "case_study_numerical = scaler.transform(test_df.loc[[case_study_index]][numerical_features])\n",
    "cs_points_sim = 1 - manhattan_distances(case_study_numerical[:, 0].reshape(-1, 1), train_numerical_scaled[:, 0].reshape(-1, 1))\n",
    "cs_value_sim = 1 - manhattan_distances(case_study_numerical[:, 2].reshape(-1, 1), train_numerical_scaled[:, 2].reshape(-1, 1))\n",
    "\n",
    "hybrid_case_study_similarity = (\n",
    "    weights['text'] * case_study_similarity_matrix +\n",
    "    weights['points'] * cs_points_sim +\n",
    "    weights['value'] * cs_value_sim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9c4e2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CASE STUDY ---\n",
      "Original Wine: Beresford 2013 Single Vineyard Chardonnay (McLaren Vale) (Chardonnay, 82 pts)\n",
      "Description: Let me confess upfront: creamed corn was one of my favorite side dishes when I was a child. That said, it's not something I like in my wine, and this medium-bodied Chardonnay shows an excess of those sweet corn and lactic aromas and flavors.\n",
      "\n",
      "--- Top 5 Recommendations ---\n",
      "1. Männle 2012 Chardonnay (Itata Valley) (Chardonnay, 80 pts) - Similarity: 0.5319\n",
      "   Description: Aromas of sweet corn and melon are not convincing. This has little in the way of mouthfeel or substance; flavors of candied fruits taste like corn and wheat, while the finish is spineless.\n",
      "   Shared Key Terms: ['aroma', 'sweet', 'like', 'corn', 'corn']\n",
      "\n",
      "2. El Enemigo 2013 Chardonnay (Mendoza) (Chardonnay, 85 pts) - Similarity: 0.5186\n",
      "   Description: This ripe offering smells of corn, baked apple and oak. It's creamy and woody in the mouth, with modest acidity. Flavors of creamed corn, caramel and soft melon finish plump, with a baked quality. It lacks vivacity.\n",
      "   Shared Key Terms: ['flavor', 'corn', 'corn', 'creamed']\n",
      "\n",
      "3. The Crossings 2009 Unoaked Chardonnay (Awatere Valley) (Chardonnay, 82 pts) - Similarity: 0.5075\n",
      "   Description: This medium-bodied Chardonnay displays some vegetal notes of canned corn and a slightly oily texture on the finish.\n",
      "   Shared Key Terms: ['chardonnay', 'mediumbodied', 'corn']\n",
      "\n",
      "4. Yangarra Estate Vineyard 2006 Single Vineyard Chardonnay (McLaren Vale) (Chardonnay, 83 pts) - Similarity: 0.4955\n",
      "   Description: Sweet corn, melon and citrus flavors coat the mouth, leaving a slightly oily impression.\n",
      "   Shared Key Terms: ['flavor', 'sweet', 'corn']\n",
      "\n",
      "5. Santa Rita 2014 Medalla Real Gran Reserva Chardonnay (Leyda Valley) (Chardonnay, 84 pts) - Similarity: 0.4876\n",
      "   Description: Aromas of corn and melon are waxy and oily. This feels pinched and juicy, but not crisp or minerally. Stalky flavors of corn, citrus and apple lean towards bitter, as does the finish.\n",
      "   Shared Key Terms: ['flavor', 'aroma', 'corn', 'corn']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case_study(case_study_index, hybrid_case_study_similarity, train_df, test_df, vectorizer=tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a7de0e",
   "metadata": {},
   "source": [
    "The hybrid model represents the most successful and balanced approach so far. It effectively uses the TF-IDF component to lock onto the key descriptive term, \"corn,\" ensuring all recommendations are stylistically similar. However, by incorporating the `points` and `value_score` features, it significantly refines the results, recommending only wines within a very tight and appropriate quality range (80-85 points). This demonstrates a clear synergy between the text and numerical features, leading to recommendations that are not just similar in flavor profile but also in their overall quality and market position. While it still doesn't understand the negative sentiment, it has proven to be the most precise model for matching a wine's complete profile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f27ccc",
   "metadata": {},
   "source": [
    "## 8. Final model selection\n",
    "\n",
    "Goal: Compare all model results and select the best one for our application.\n",
    "\n",
    "### Model Comparison Summary\n",
    "\n",
    "| Model                       | Variety Match Rate | Country Match Rate | Avg. Point Differential | Qualitative Notes                                                              |\n",
    "|-----------------------------|--------------------|--------------------|-------------------------|--------------------------------------------------------------------------------|\n",
    "| **1. TF-IDF** | 93.00%             | 98.60%             | 1.70 pts                | Excellent at keyword matching, but lacks semantic understanding (e.g., sentiment). |\n",
    "| **2. Sentence Transformer** | 89.30%             | 97.10%             | 1.88 pts                | Better at capturing overall style, but less precise on explicit facts.         |\n",
    "| **3. Custom Word2Vec** | 83.40%             | 97.30%             | 1.60 pts                | Best at matching quality tier, understands nuanced/negative language.          |\n",
    "| **4. Hybrid Model** | 93.90% | 99.10% | 0.72 pts | Best of all worlds: precise, quality-aware, and stylistically relevant.        |\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "After a comprehensive evaluation, the Custom Hybrid Model is the clear winner. It outperforms all other models on every quantitative metric, achieving the highest match rates for variety and country while maintaining an exceptionally low average point differential. The qualitative analysis confirms that by combining the keyword-matching strength of TF-IDF with the engineered features for quality and value, the hybrid model provides recommendations that are not only stylistically similar but also precisely matched in terms of quality and market position. This balanced and highly accurate approach makes it the ideal choice for the final VinoMatch application. We will now proceed with saving this model and its components for use in our Streamlit app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cc5edd",
   "metadata": {},
   "source": [
    "## 9. Save the final model and data\n",
    "\n",
    "Goal: Save the components of our chosen model (Hybrid Model) for the Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d80a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5077790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TF-IDF vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4490acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scaler\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71313e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The similarity matrix will be computed on the fly in the app,\n",
    "# but we need the train vectors and numerical features.\n",
    "np.save('tfidf_train_vectors.npy', tfidf_train_vectors.toarray())\n",
    "np.save('train_numerical_scaled.npy', train_numerical_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cb5086",
   "metadata": {},
   "source": [
    "## Conclusion and key insights\n",
    "\n",
    "This notebook successfully executed the core experimental phase of the project. After rigorously testing four different models, the Custom Hybrid Model emerged as the definitive winner. While simpler models like TF-IDF performed well on basic keyword matching, and semantic models showed a nuanced understanding of quality, the hybrid approach delivered the best of all worlds. It achieved the highest scores across all quantitative metrics, most notably reducing the average point differential to just 0.72, while the qualitative case study confirmed its ability to provide stylistically relevant recommendations within the correct quality tier. This data-driven process gives us high confidence in our final model choice. The next and final step is to take the saved components of this winning model and build the interactive Streamlit application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
